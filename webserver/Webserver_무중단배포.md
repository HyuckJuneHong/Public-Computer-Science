# 웹서버와 무중단 배포

---

---

# 1. Web Server

### 1-1. 웹 서버란?

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled.png)

- **하드웨어 측면** :  웹서버의 소프트웨어와 웹사이트의 컴포넌트 파일들을 저장하는 컴퓨터이다.
- **소프트웨어 측면** :  기본적으로 웹 사용자가 어떻게 호스트 파일들에 접근하는 지를 관리한다.
- **보통 많이 쓰이는 웹서버 프로그램** : Apache & Nginx
- 웹서버는 HTTP 요청을 읽어 응답을 해주는 프로그램이다.
- 웹서버 프로그램을 서버 상에 설치하여 특정 HTTP 요청에 따라 서비스를 제공해주는 방식으로 웹서비스를 구현한다.

### 1-2. **웹서버의 흐름**

1. 브라우저가 웹서버에 불려진 파일들을 필요로 하는 상태.
2. 브라우저가 HTTP를 통해 필요로 하는 파일을 요청.
3. 해당 요청이 웹서버. 즉, 하드웨어에 도달한다.
4. 해당 요청 문서 HTTP를 이용해 소프트웨어인 HTTP 서버에 응답한다.

---

# 2. **Apache**

### 2-1. 아파치란?

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%201.png)

- 거의 모든 O.S에서 실행되고 있다.
- Apache는 오픈 소스 프로젝트로 가장 유명한 프로그램 중 하나이다.
- 통합 지원 등의 이점이 있다.

### 2-2. **주요 특징**

- 스레드 / 프로세스 기반 구조이다.
- 클라이언트 요청 당 하나의 스레드 처리 구조이다. 때문에, 사용자가 많으면 스레드 생성, 메모리 및 CPU 낭비가 증가한다.
- 구동 방식은 MPM(Multi-Process Module) 방식이다.
- 동적 컨텐츠 처리한다.
- 다양한 모듈이 있다.

### 2-3. **대표적인 구동 방식 종류**

- **Prefork MPM 방식 (다중 프로세스 방식) → Default 값**
    - 클라이언트 요청에 대해 자식 프로세스를 생성하여 처리하는 방식이다.
        - 하나의 자식 프로세스 당 하나의 스레드를 가진다. / 최대 1024개
        - 즉, HTTP 요청이 들어올 때마다, 프로세스를 복제하여, 각 별도의 프로레스에서 해당 HTTP 요청을 처리한다.
    - 스레드간 메모리 공유를 하지 않는다. 즉, 독립적이고 안정적이다. 단, 메모리 소모가 크다.
- **Worker MPM 방식 (멀티 프로레스-스레드 방식)**
    - 각 프로세스의 스레드를 생성해 처리하는 구조이다.
        - 즉, 하나의 HTTP 연결 후 여러 요청을 처리하기 위해 복제된 프로세스 내에서 여러 쓰레드를 생성하고 여러 HTTP 요청을 처리하는 방식이다.
    - PreFork보다 메모리 사용량이 적고 동시 접속자가 많은 사이트에 사용하는 방식이다.
    - 스레드 간 메모리 공유가 가능하고 프로세스 당 최대 64개의 스레드 처리가 가능하다.
        - 각 스레드는 하나의 연결만을 부여 받는다.

### 2-4. **단점**

- 클라이언트 접속마다 프로세스 또는 스레드를 생성하는 구조이다.,
    - 때문에, 대량의 클라이언트(1만개 이상, C10K)가 동시에 접속하면 CPU/Memory 사용이 증가하고 프로세스/스레드 생성 비용이 드는 등 요청에 한계가 있다.
- 아파치 서버의 프로세스가 Blocking 이 되면 요청을 처리하지 못하고 처리가 완료될 때까지 계속 대기해야 한다.
    - 이 문제점은, Keep Alive(접속 대기)를 이용해 해결이 가능하다.
    - 하지만, Keep Alive로 인해 대량 접속 시 효율이 떨어진다.

---

# 3. Nginx

### 3-1. 엔진엑스란?

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%202.png)

- 아파치의 C10K 문제점 해결을 위해 만들어진 Event-Driven 구조의 웹서버 소프트웨어이다.
    - **C10K** : 1만개 클라이언트 문제
    - **Event-Driven** :  프로그램의 흐름이 이벤트에 의해 결정되는 방식
- 경량 웹 서버이다.
- 클라이언트로부터 요청을 받았을 때 요청에 맞는 정적 파일을 응답해주는 HTTP Web Server 로 활용된다.
- Reverse Proxy Server 로 활용하여 WAS 서버의 부하를 줄일 수 있는 LB 역할로 활용하기도 한다.

### 3-2. **주요 특징**

- **이벤트-드라이븐 처리 기반 구조이다.**
    - 아파치와 달리 동시 접속자 수가 많아도 추가적인 생성 비용이 들지 않는다.
        - CPU와 관계 없이 I/O들은 전부 이벤트리스너로 미루기 때문에, 흐름이 끊기지 않고 응답이 빠르게 진행되어 1개의 프로세스로 더 빠른 작업이 가능하다.
    - HTTP 요청마다 프로세스든 쓰레드든 생성이 필요 없으므로 시스템 자원 관리가 용이하다.
        - 하지만, HTML 파일 사이즈, 어떤 추가 기능 등을 쓰느냐에 다양한 조건이 있기 때문에, 무조건적으로 성능이 좋다고는 할 수 없다.
- **하나의 프로세스로 동작하고 HTTP 요청을 이벤트로 비동기 처리한다.**
    - 커넥션을 전부 이벤트 핸들러를 통해 비동기 방식으로 처리
    - 대부분의 HTTP 응답은 HTML 파일을 제공하는 것이므로 I/O 작업이기 때문에, I/O 작업으로 이벤트를 포워딩하고 요청 순이 아닌, 요청 작업이 끝나는 순으로 처리한다.
- **리버스 프록시 배치가 가능하다.**
    - 엔진엑스의 빠른 처리 속도를 활용하여 클라이언트의 모든 요청을 처리한다.

### 3-3. **동작 과정**

- 사전에 서버 개발자가 정한 스레드 개수를 생성하고 해당 자원만을 가지고 HTTP 요청을 처리한다.
- Event-Driven 구조로 동작하기 때문에 요청을 처리할 때 다른 작업이 끝남을 기다리지 않고 비동기 방식으로 동작한다.

### 3-4. **Event-Driven 구조 동작 방식**

- Nginx 는 요청에 대한 작업을 처리할 때, CPU 가 관여하지 않는 작업(I/O, socket read/write)을 하면 해당 작업은 스레드가 작업 하지 않고 이벤트 핸들러라는 곳으로 보내 작업한다.
- 이벤트 핸들러는 작업을 마치게 되면 작업이 완료된 순서대로 큐에 보관한다.
- 매번 이벤트 루프가 큐를 확인하면서 완료된 작업이 있는지 확인한다.
- 큐에 있는 값을 응답한다.

### 3-5. **단점**

- 동적 컨텐츠를 기본적으로 처리할 수 없다.
    - 동적 컨텐츠를 처리하려면 외부 프로세서로 전달하고 렌더링된 컨텐츠를 다시 전송할 때까지 기다려야 한다.
    - 때문에, 프로세스 속도가 저하된다.
- 아파치에 비해 모듈이 적다.

### 3-6. **엔진엑스는 어떻게 싱글 스레드로 대용량의 효율을 뽑아낼까?**

- 하나의 master 프로세스에서 고정된 수의 worker 프로세스만을 관리한다.
    - worker 프로세스는 보통 CPU 코어 개수만큼 생성
    - worker 프로세스는 Block 되지 않고 listen socket과 Connection Socket의 이벤트를 기반으로 Non-Blocking 으로 동작한다.
    - 즉, worker 프로세스들이 listen socket과 Connection Socket 2개의 이벤트를 다 처리한다.
- 매 connection 마다 프로세스나 스레드를 생성하지 않고 고정된 수의 프로세스로 여러 connection 을 처리하기 위해 이벤트가 발생할 때마다 처리해주는 방식으로 동작한다.
- worker 프로세스는 nginx 설정에 따라 초기화되고 master process 에 의해 listen socket 을 제공받는다.
- 새로운 connection 이 들어오면 이벤트가 발생하고 connection 종류에 따라 알맞은 기계 상태가 할당된다.
    - 기계 상태
        - Http State machine
        - Stream State machine : raw TCP
        - Mail state machine : SMTP / IMAP / POP3

### 3-7. **이벤트 주도 방식이 더 빠른 이유**

- 아파치는 메모리에 프로세스 스레드를 생성하기 위한 공간이 필요하다. 또한 해당 프로세스나 스레드를 관리하기 위해서 추가적인 CPU 작업이 필요하다. 따라서, 이러한 작업 수가 많아질수록 콘텍스트 스위칭이 많아진다. 때문에 이벤트 주도 방식이 더 빠르다.

---

# 4. 정리

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%203.png)

---

# 5. 무중단 배포

### 5-1. 무중단 배포란?

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%204.png)

- 서비스가 운영 중일 때 새로운 버전을 배포한다고 가정해보면 다음과 같을 것이다.
    1. 기존 서비스를 종료한다.
    2. 새로운 서비스를 시작한다.
    - 즉, 1번과 2번의 과정에서 Downtime이 발생한다.
    - 이 말은 사용자들이 Downtime 동안 서비스를 이용할 수 없게 된다.
- 이 때, 이 Downtime 을 해결해주는 것이 무중단 배포이다.
    - 즉, 중단이 없는 배포를 무중단 배포로 새로운 버전을 사용자들에게 배포하는 것을 의미.
    - 단, 무중단 배포는 최소 서버가 2대 이상을 확보해야 한다.

### 5-2. 무중단 배포 구현 방식 종류

- AWS의 Blue-Green 무중단 배포 방식
- Docker를 활용한 무중단 배포 방식
- L4, L7 스위치를 활용한 무중단 배포
- Nginx(웹 서버)를 활용한 무중단 배포

---

## 5-3. 대표적인 무중단 배포 전략

### 5-3-1. Rolling 배포 전략

- 트래픽을 점진적으로 구버전에서 신버전으로 교체하는 방식으로 가장 기본적인 방식이다.
    - 이때, 점진적으로 버전을 교체하는 방법은 레퍼런스마다 다르지만 크게 2가지 방식이 있다.

**먼저, 첫 번째 방식이다.**

- 인스턴스를 하나 추가하고 새로운 버전을 실행한다.
- 그 다음, 로드 밸런서에 새로 추가한 인스턴스를 연결하고 기존 구 버전 인스턴스를 없앤다.

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%205.png)

이처럼, 서버 개수를 유연하게 조절할 수 있는 AWS와 같은 클라우드를 기반으로 서비스를 운영할 때 적합하다.

**두 번째 방식이다.**

- 실행되고 있는 서버 하나를 로드밸런서에서 떼어낸다.
- 떼어낸 해당 서버에는 트래픽이 도달하지 않게 되는데, 이 상태에서 해당 서버의 어플리케이션을 V2로 교체한다.

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%206.png)

이런 방식은 클라우드 환경이 아닌 물리적인 서버로 서비스를 운영하는 상황에 사용할 수 있을 것이다.

**장점**

- Elastic Beanstalk 같은 도구에서 지원이 간편한다.
- 많은 서버 자원을 확보하지 않아도 무중단 배포가 가능하다.
- 점진적으로 새로운 버전을 사용자에게 출시하므로, 배포로 인한 위험성이 다소 줄어들 수 있다.

**단점**

- 두 번째 방식 같은 방식으로 배포 도중 서비스 중인 인스턴스의 수가 줄어들어 각 서버가 부담하는 트래픽 양이 늘어날 수 있다.
    - 따라서, 전체 트래픽의 양과 단일 서버가 처리할 수 있는 트래픽 양을 잘 파악하여 진행해야 한다.
    - 즉, 서버 수의 제약이 있을 경우 유용하지만, 배포 중 인스턴스 수가 감소하므로, 서버 처리 용량을 고려해야한다.
- 구버전과 신버전의 어플리케이션이 동시에 서비스가 되기 때문에 호환성 문제가 발생할 수 있다.

---

### 5-3-2. Blue - Green 배포 전략

- 트래픽을 한번에 구버전에서 신버전으로 전환하는 전략이다.
- 현재 운영 중인 서비스의 환경을 Blue라고 한다.
- 새롭게 배포할 서비스의 환경을 Green이라 한다.
- 즉, Blue와 Green의 서버를 동시에 나란히 구성해둔 상태에서 배포 시점에 로드 밸런서가 트래픽을 Blue에서 Green으로 일제히 전환한다.
- 이때, Green 버전 배포가 성공적으로 완료 되어 문제가 없다고 판단 시 Blue 서버를 제거하거나 다음 배포를 위해 유지할 수 있다.

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%207.png)

**장점**

- 롤링 배포와 달리 한번에 트래픽을 모두 새로운 버전으로 옮기기 때문에 호환성 문제가 발생하지 않는다.
- 운영 환경에 영향을 주지 않고 실제 서비스 환경에서 테스트가 가능하다.
    - 예로 구버전과 신버전 모두 구성하고 포트를 다르게 주거나, 내부 트래픽일 경우 신버전으로 접근하도록 설정하여 테스트를 진행할 수 있다.

**단점**

- 실제 운영에 필요한 서버 리소스 대시 2배의 리소스를 확보해야 한다. 즉, 시스템 자원이 두배로 필요하다.
- 따라서 클라우드 환경에서 운영한다면 필요없는 인스턴스를 제거하면 그만이지만, 온프레미스 방식으로 서비스를 운영했다면 비용 부담이 클 것이다.

---

### 카나리(Canary) 배포 전략

- 점진적으로 구버전에 대한 트래픽을 신버전으로 옮기는 것은 롤링 배포 방식과 비슷하지만 카나리 배포 전략은 새로운 버전에 대한 오류를 조기에 감지하는 것이다.
    - 즉, 위험을 빠르게 감지하는 배포 전략이다.
- 구버전과 신버전의 서버들을 구성하고 일부 트래픽을 신버전으로 분산하면서 오류를 검출한다.
    - 즉, 소수 인원에 대해서만 트래픽을 새로운 버전에 옮겨둔 상태에서 서비스를 운영한다.
    - 이때, 새로운 버전에 이상이 없다고 판단 시, 모든 트래픽을 신규 버전으로 옮긴다.
    - 신규 버전으로 옮기는 기준은 정해진 규칙이 있거나 랜덤이다.
    - 어쨌든 분산 후 결과에 따라 신버전으로 대체할 수도 있고 다시 구버전으로 돌아갈 수도 있다.
- A/B 테스트를 진행하기에도 적합하다.

![Untitled](%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%8B%E1%85%AA%20%E1%84%86%E1%85%AE%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%83%E1%85%A1%E1%86%AB%20%E1%84%87%E1%85%A2%E1%84%91%E1%85%A9%2095acdde689f34963b68ae357091debe0/Untitled%208.png)

**장점**

- 새로운 버전으로 인한 위험을 최소화할 수 있다.

**단점**

- 롤링 배포와 마찬가지로 신/구 버전의 애플리케이션이 동시에 존재하므로 호환성 문제가 발생할 수 있다.

---

# <참조>

[무중단 배포 아키텍처[Zero Downtime Deployment] - 글로벌 서비스 운영의 필수 요소 | 인사이트리포트 | 삼성SDS](https://www.samsungsds.com/kr/insights/1256264_4627.html)